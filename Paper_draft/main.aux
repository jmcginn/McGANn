\relax 
\providecommand\hyper@newdestlabel[2]{}
\bibstyle{iopart-num_custom}
\AC@reset@newl@bel
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Abbott2016}
\citation{Prospects-dets}
\citation{AdvLIGO}
\citation{AdvLIGO2}
\citation{AdvVIRGO}
\citation{Abbott2016a}
\citation{Abbott2017}
\citation{Abbott2017a}
\citation{Abbott2017b}
\citation{Owen1998}
\providecommand \oddpage@label [2]{}
\newacro{GW}[GW]{Gravitational wave}
\newacro{GAN}[GAN]{generative adversarial network}
\newacro{CGAN}[CGAN]{conditional generative adversarial network}
\newacro{ACGAN}[ACGAN]{auxilliary conditional generative adversarial network}
\newacro{DCGAN}[DCGAN]{deep convolutional generative adversarial network}
\newacro{CNN}[CNN]{convolutional neural networks}
\newacro{BBH}[BBH]{binary black hole}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{Klimenko_2008}
\citation{Aso_2008}
\citation{Gabbard2017}
\citation{Gebhard_2019}
\citation{Krastev_2020}
\citation{Bahaadini}
\citation{George_2018}
\citation{Razzano_2018}
\citation{gabbard2019bayesian}
\citation{shen2019deterministic}
\citation{green2020gravitationalwave}
\AC@undonewlabel{acro:GW}
\newlabel{acro:GW}{{1}{2}{Introduction}{section*.1}{}}
\newlabel{acro:GW@cref}{{[section][1][]1}{[1][2][]2}}
\acronymused{GW}
\acronymused{GW}
\acronymused{GW}
\acronymused{GW}
\acronymused{GW}
\acronymused{GW}
\acronymused{GW}
\@writefile{toc}{\contentsline {section}{\numberline {2}Generative Adversarial Networks}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Artificial neural networks}{2}{subsection.2.1}\protected@file@percent }
\newlabel{fig:perceptron}{{1a}{3}{Subfigure 1a}{subfigure.1.1}{}}
\newlabel{sub@fig:perceptron}{{(a)}{a}{Subfigure 1a\relax }{subfigure.1.1}{}}
\newlabel{fig:perceptron@cref}{{[subfigure][1][1]1a}{[1][2][]3}}
\newlabel{fig:tanh_activation}{{1b}{3}{Subfigure 1b}{subfigure.1.2}{}}
\newlabel{sub@fig:tanh_activation}{{(b)}{b}{Subfigure 1b\relax }{subfigure.1.2}{}}
\newlabel{fig:tanh_activation@cref}{{[subfigure][2][1]1b}{[1][2][]3}}
\newlabel{fig:neural_network}{{1c}{3}{Subfigure 1c}{subfigure.1.3}{}}
\newlabel{sub@fig:neural_network}{{(c)}{c}{Subfigure 1c\relax }{subfigure.1.3}{}}
\newlabel{fig:neural_network@cref}{{[subfigure][3][1]1c}{[1][2][]3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Neural Networks (a) A single neuron taking a vector of inputs and returning a singular output based on the weights, bias and activation function of the network. (b) The hyperbolic tangent used as an activation function. (c) A fully connected neural network containing two hidden layers that performs a mapping of an input vector to a singular output. \textbf  {\leavevmode {\color  {orange}MICHAEL: Equation in the neuron looks very small}}\relax }}{3}{figure.caption.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{3}{subfigure.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{3}{subfigure.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{3}{subfigure.1.3}\protected@file@percent }
\newlabel{eqn:neuron}{{1}{3}{Artificial neural networks}{equation.2.1}{}}
\newlabel{eqn:neuron@cref}{{[equation][1][]1}{[1][3][]3}}
\citation{Goodfellow2014}
\citation{brock2018large}
\citation{karras2019analyzing}
\citation{reed2016generative}
\citation{liang2017dual}
\citation{esteban2017realvalued}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}GANs}{4}{subsection.2.2}\protected@file@percent }
\AC@undonewlabel{acro:GAN}
\newlabel{acro:GAN}{{2.2}{4}{GANs}{section*.3}{}}
\newlabel{acro:GAN@cref}{{[subsection][2][2]2.2}{[1][4][]4}}
\acronymused{GAN}
\acronymused{GAN}
\acronymused{GAN}
\acronymused{GAN}
\newlabel{equation:GANloss}{{2}{4}{GANs}{equation.2.2}{}}
\newlabel{equation:GANloss@cref}{{[equation][2][]2}{[1][4][]4}}
\citation{Nash1950}
\citation{cgan}
\citation{isola2016imagetoimage}
\citation{Khan_2016}
\citation{lalsuite}
\citation{Abbott_2019}
\acronymused{GAN}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Conditional GANs}{5}{subsection.2.3}\protected@file@percent }
\acronymused{GAN}
\AC@undonewlabel{acro:CGAN}
\newlabel{acro:CGAN}{{2.3}{5}{Conditional GANs}{section*.4}{}}
\newlabel{acro:CGAN@cref}{{[subsection][3][2]2.3}{[1][5][]5}}
\acronymused{CGAN}
\newlabel{equation:cGANloss}{{3}{5}{Conditional GANs}{equation.2.3}{}}
\newlabel{equation:cGANloss@cref}{{[equation][3][]3}{[1][5][]5}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{5}{section.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Burst training parameters\relax }}{5}{table.caption.6}\protected@file@percent }
\newlabel{Tab:training_parms}{{1}{5}{Burst training parameters\relax }{table.caption.6}{}}
\newlabel{Tab:training_parms@cref}{{[table][1][]1}{[1][5][]5}}
\citation{Radford2015}
\citation{DBLP:journals/corr/abs-1809-11096}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Comparison of the original GAN method and the Conditional-GAN method. For CGANs the training data requires a label denoting its class that is also fed to the generator which then learns to generate waveforms based on the input label.\relax }}{6}{figure.caption.5}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:gan_comparison}{{2}{6}{Comparison of the original GAN method and the Conditional-GAN method. For CGANs the training data requires a label denoting its class that is also fed to the generator which then learns to generate waveforms based on the input label.\relax }{figure.caption.5}{}}
\newlabel{fig:gan_comparison@cref}{{[figure][2][]2}{[1][5][]6}}
\acronymused{GAN}
\AC@undonewlabel{acro:BBH}
\newlabel{acro:BBH}{{3}{6}{Methodology}{section*.7}{}}
\newlabel{acro:BBH@cref}{{[section][3][]3}{[1][5][]6}}
\acronymused{BBH}
\citation{Radford2015}
\citation{DBLP:journals/corr/abs-1809-11096}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Examples of simulated \ac {GW} burst signals. Top row shows examples from the training set. From left to right: Sine-Gaussian, Ringdown, White-noise burst, Gaussian pulse, Binary black hole merger. The bottom row shows the conditional generations from the GAN. Each plots contains only one detector output for ease of viewing.\relax }}{7}{figure.caption.8}\protected@file@percent }
\acronymused{GW}
\newlabel{fig:train}{{3}{7}{Examples of simulated \ac {GW} burst signals. Top row shows examples from the training set. From left to right: Sine-Gaussian, Ringdown, White-noise burst, Gaussian pulse, Binary black hole merger. The bottom row shows the conditional generations from the GAN. Each plots contains only one detector output for ease of viewing.\relax }{figure.caption.8}{}}
\newlabel{fig:train@cref}{{[figure][3][]3}{[1][6][]7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Architecture details}{7}{subsection.3.1}\protected@file@percent }
\acronymused{GAN}
\AC@undonewlabel{acro:DCGAN}
\newlabel{acro:DCGAN}{{3.1}{7}{Architecture details}{section*.9}{}}
\newlabel{acro:DCGAN@cref}{{[subsection][1][3]3.1}{[1][6][]7}}
\acronymused{DCGAN}
\acronymused{GAN}
\AC@undonewlabel{acro:CNN}
\newlabel{acro:CNN}{{3.1}{7}{Architecture details}{section*.10}{}}
\newlabel{acro:CNN@cref}{{[subsection][1][3]3.1}{[1][6][]7}}
\acronymused{CNN}
\acronymused{GAN}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{8}{section.4}\protected@file@percent }
\acronymused{GW}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Waveform quality}{8}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Interpolation}{8}{subsection.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Generated waveforms after training and conditioning on five classes. The generator will output two waveforms as seen by detectors in Hanford (red) and Livingston (blue). The generator is able to capture the characteristics of each waveform and structure the class space to give control over which waveform to generate. Each row shows a random assortment of one of the five classes the GAN is trained on. \relax }}{9}{figure.caption.11}\protected@file@percent }
\newlabel{fig:gen_signals}{{4}{9}{Generated waveforms after training and conditioning on five classes. The generator will output two waveforms as seen by detectors in Hanford (red) and Livingston (blue). The generator is able to capture the characteristics of each waveform and structure the class space to give control over which waveform to generate. Each row shows a random assortment of one of the five classes the GAN is trained on. \relax }{figure.caption.11}{}}
\newlabel{fig:gen_signals@cref}{{[figure][4][]4}{[1][8][]9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Latent space interpolation}{10}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Class space interpolation}{10}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Vector Arithmetic}{10}{subsection.4.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Interpolations between two random latent points in z. Each row uniformly interpolates between two points in $\mathbf  {z}$ keeping the class fixed. Only a single waveform from the generator is plotted and each signal is re-scaled to [-1,1] effectively removing the antenna responses for clarity.\relax }}{11}{figure.caption.12}\protected@file@percent }
\newlabel{fig:z_interp}{{5}{11}{Interpolations between two random latent points in z. Each row uniformly interpolates between two points in $\mathbf {z}$ keeping the class fixed. Only a single waveform from the generator is plotted and each signal is re-scaled to [-1,1] effectively removing the antenna responses for clarity.\relax }{figure.caption.12}{}}
\newlabel{fig:z_interp@cref}{{[figure][5][]5}{[1][10][]11}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Class space interpolation with latent space held constant throughout. The plots show a zoomed in section of the 1s time interval. First row: Sine-Gaussian class to ringdown class, Second Row: Sine-Gaussian class to whitenoise burst class, Third row: Sine-Gaussian class to Gaussian class, Fourth row: Sine-Gaussian to BBH class.\relax }}{12}{figure.caption.13}\protected@file@percent }
\newlabel{fig:c_interp}{{6}{12}{Class space interpolation with latent space held constant throughout. The plots show a zoomed in section of the 1s time interval. First row: Sine-Gaussian class to ringdown class, Second Row: Sine-Gaussian class to whitenoise burst class, Third row: Sine-Gaussian class to Gaussian class, Fourth row: Sine-Gaussian to BBH class.\relax }{figure.caption.13}{}}
\newlabel{fig:c_interp@cref}{{[figure][6][]6}{[1][10][]12}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Class space interpolation with latent space held constant throughout. The full 1s interval is plotted for class based interpolations between a Sine-Gaussian and a BBH in spiral.\relax }}{13}{figure.caption.14}\protected@file@percent }
\newlabel{fig:sgbbh_interp}{{7}{13}{Class space interpolation with latent space held constant throughout. The full 1s interval is plotted for class based interpolations between a Sine-Gaussian and a BBH in spiral.\relax }{figure.caption.14}{}}
\newlabel{fig:sgbbh_interp@cref}{{[figure][7][]7}{[1][10][]13}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Conditional vector arithmetic. (a) Generated samples of a whitenoise burst and BBH insprial. (c) Effect of naively adding the components from (a) in the time domain. \textbf  {\leavevmode {\color  {red}JORDAN: just adding the two signals post generation}} (c) Generation from the combined class vectors. \relax }}{13}{figure.caption.15}\protected@file@percent }
\newlabel{fig:arithmetic}{{8}{13}{Conditional vector arithmetic. (a) Generated samples of a whitenoise burst and BBH insprial. (c) Effect of naively adding the components from (a) in the time domain. \jordan {just adding the two signals post generation} (c) Generation from the combined class vectors. \relax }{figure.caption.15}{}}
\newlabel{fig:arithmetic@cref}{{[figure][8][]8}{[1][11][]13}}
\bibdata{iopart-num}
\bibcite{Abbott2016}{1}
\bibcite{Prospects-dets}{2}
\bibcite{AdvLIGO}{3}
\bibcite{AdvLIGO2}{4}
\bibcite{AdvVIRGO}{5}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Classifier}{14}{subsection.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusions}{14}{section.5}\protected@file@percent }
\acronymused{GW}
\bibcite{Abbott2016a}{6}
\bibcite{Abbott2017}{7}
\bibcite{Abbott2017a}{8}
\bibcite{Abbott2017b}{9}
\bibcite{Owen1998}{10}
\bibcite{Klimenko_2008}{11}
\bibcite{Aso_2008}{12}
\bibcite{Gabbard2017}{13}
\bibcite{gabbard2019bayesian}{14}
\bibcite{Goodfellow2014}{15}
\bibcite{brock2018large}{16}
\bibcite{karras2019analyzing}{17}
\bibcite{reed2016generative}{18}
\bibcite{liang2017dual}{19}
\bibcite{esteban2017realvalued}{20}
\bibcite{Nash1950}{21}
\bibcite{cgan}{22}
\bibcite{odena2016conditional}{23}
\bibcite{Radford2015}{24}
\bibcite{DBLP:journals/corr/abs-1809-11096}{25}
\bibcite{lalsuite}{26}
\@writefile{toc}{\contentsline {section}{\numberline {Appendix A}List of hyperparameters}{16}{appendix.A}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {A1}{\ignorespaces ACGAN architecture\relax }}{16}{table.caption.17}\protected@file@percent }
\newlabel{Tab:hyperparameters}{{A1}{16}{ACGAN architecture\relax }{table.caption.17}{}}
\newlabel{Tab:hyperparameters@cref}{{[table][1][2147483647,1]A1}{[1][16][]16}}
\@writefile{toc}{\contentsline {section}{\numberline {Appendix B}Many more generated examples}{16}{appendix.B}\protected@file@percent }
