\relax 
\providecommand\hyper@newdestlabel[2]{}
\bibstyle{iopart-num_custom}
\AC@reset@newl@bel
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Abbott2016}
\citation{Prospects-dets}
\citation{AdvLIGO}
\citation{AdvLIGO2}
\citation{AdvVIRGO}
\citation{Abbott2016a}
\citation{Abbott2017}
\citation{Abbott2017a}
\citation{Abbott2017b}
\citation{Fryer_2003}
\citation{Andersson_2001}
\citation{Baiotti_2007}
\citation{Owen1998}
\providecommand \oddpage@label [2]{}
\newacro{GW}[GW]{Gravitational wave}
\newacro{GAN}[GAN]{generative adversarial network}
\newacro{CGAN}[CGAN]{conditional generative adversarial network}
\newacro{ACGAN}[ACGAN]{auxilliary conditional generative adversarial network}
\newacro{DCGAN}[DCGAN]{deep convolutional generative adversarial network}
\newacro{CNN}[CNN]{convolutional neural networks}
\newacro{BBH}[BBH]{binary black hole}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{Klimenko_2008}
\citation{Aso_2008}
\citation{Gabbard2017}
\citation{Gebhard_2019}
\citation{Krastev_2020}
\citation{Bahaadini}
\citation{George_2018}
\citation{Razzano_2018}
\citation{gabbard2019bayesian}
\citation{shen2019deterministic}
\citation{green2020gravitationalwave}
\AC@undonewlabel{acro:GW}
\newlabel{acro:GW}{{1}{2}{Introduction}{section*.1}{}}
\newlabel{acro:GW@cref}{{[section][1][]1}{[1][2][]2}}
\acronymused{GW}
\acronymused{GW}
\acronymused{GW}
\acronymused{GW}
\acronymused{GW}
\acronymused{GW}
\acronymused{GW}
\@writefile{toc}{\contentsline {section}{\numberline {2}Generative Adversarial Networks}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Artificial neural networks}{2}{subsection.2.1}\protected@file@percent }
\newlabel{fig:perceptron}{{1a}{3}{Subfigure 1a}{subfigure.1.1}{}}
\newlabel{sub@fig:perceptron}{{(a)}{a}{Subfigure 1a\relax }{subfigure.1.1}{}}
\newlabel{fig:perceptron@cref}{{[subfigure][1][1]1a}{[1][2][]3}}
\newlabel{fig:tanh_activation}{{1b}{3}{Subfigure 1b}{subfigure.1.2}{}}
\newlabel{sub@fig:tanh_activation}{{(b)}{b}{Subfigure 1b\relax }{subfigure.1.2}{}}
\newlabel{fig:tanh_activation@cref}{{[subfigure][2][1]1b}{[1][2][]3}}
\newlabel{fig:neural_network}{{1c}{3}{Subfigure 1c}{subfigure.1.3}{}}
\newlabel{sub@fig:neural_network}{{(c)}{c}{Subfigure 1c\relax }{subfigure.1.3}{}}
\newlabel{fig:neural_network@cref}{{[subfigure][3][1]1c}{[1][2][]3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Neural Networks (a) A single neuron taking a vector of inputs and returning a singular output based on the weights, bias and activation function of the network. (b) The hyperbolic tangent used as an activation function. (c) A fully connected neural network containing two hidden layers that performs a mapping of an input vector to a singular output. \textbf  {\leavevmode {\color  {orange}MICHAEL: Equation in the neuron looks very small}}\relax }}{3}{figure.caption.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{3}{subfigure.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{3}{subfigure.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{3}{subfigure.1.3}\protected@file@percent }
\newlabel{eqn:neuron}{{1}{3}{Artificial neural networks}{equation.2.1}{}}
\newlabel{eqn:neuron@cref}{{[equation][1][]1}{[1][3][]3}}
\citation{Goodfellow2014}
\citation{brock2018large}
\citation{karras2019analyzing}
\citation{reed2016generative}
\citation{liang2017dual}
\citation{esteban2017realvalued}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Convolutional Neural Networks}{4}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}GANs}{4}{subsection.2.3}\protected@file@percent }
\AC@undonewlabel{acro:GAN}
\newlabel{acro:GAN}{{2.3}{4}{GANs}{section*.3}{}}
\newlabel{acro:GAN@cref}{{[subsection][3][2]2.3}{[1][4][]4}}
\acronymused{GAN}
\acronymused{GAN}
\acronymused{GAN}
\citation{Nash1950}
\citation{cgan}
\citation{isola2016imagetoimage}
\acronymused{GAN}
\newlabel{equation:GANloss}{{2}{5}{GANs}{equation.2.2}{}}
\newlabel{equation:GANloss@cref}{{[equation][2][]2}{[1][5][]5}}
\acronymused{GAN}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Conditional GANs}{5}{subsection.2.4}\protected@file@percent }
\acronymused{GAN}
\AC@undonewlabel{acro:CGAN}
\newlabel{acro:CGAN}{{2.4}{5}{Conditional GANs}{section*.4}{}}
\newlabel{acro:CGAN@cref}{{[subsection][4][2]2.4}{[1][5][]5}}
\acronymused{CGAN}
\newlabel{equation:cGANloss}{{3}{5}{Conditional GANs}{equation.2.3}{}}
\newlabel{equation:cGANloss@cref}{{[equation][3][]3}{[1][5][]5}}
\citation{Khan_2016}
\citation{lalsuite}
\citation{Abbott_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Comparison of the original GAN method and the Conditional-GAN method. For CGANs the training data requires a label denoting its class that is also fed to the generator which then learns to generate waveforms based on the input label.\relax }}{6}{figure.caption.5}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:gan_comparison}{{2}{6}{Comparison of the original GAN method and the Conditional-GAN method. For CGANs the training data requires a label denoting its class that is also fed to the generator which then learns to generate waveforms based on the input label.\relax }{figure.caption.5}{}}
\newlabel{fig:gan_comparison@cref}{{[figure][2][]2}{[1][5][]6}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{6}{section.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Burst training parameters\relax }}{6}{table.caption.6}\protected@file@percent }
\newlabel{Tab:training_parms}{{1}{6}{Burst training parameters\relax }{table.caption.6}{}}
\newlabel{Tab:training_parms@cref}{{[table][1][]1}{[1][5][]6}}
\acronymused{GAN}
\citation{Radford2015}
\citation{DBLP:journals/corr/abs-1809-11096}
\citation{Radford2015}
\citation{DBLP:journals/corr/abs-1809-11096}
\AC@undonewlabel{acro:BBH}
\newlabel{acro:BBH}{{3}{7}{Methodology}{section*.7}{}}
\newlabel{acro:BBH@cref}{{[section][3][]3}{[1][6][]7}}
\acronymused{BBH}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Architecture details}{7}{subsection.3.1}\protected@file@percent }
\acronymused{GAN}
\AC@undonewlabel{acro:DCGAN}
\newlabel{acro:DCGAN}{{3.1}{7}{Architecture details}{section*.8}{}}
\newlabel{acro:DCGAN@cref}{{[subsection][1][3]3.1}{[1][7][]7}}
\acronymused{DCGAN}
\acronymused{GAN}
\AC@undonewlabel{acro:CNN}
\newlabel{acro:CNN}{{3.1}{7}{Architecture details}{section*.9}{}}
\newlabel{acro:CNN@cref}{{[subsection][1][3]3.1}{[1][7][]7}}
\acronymused{CNN}
\acronymused{GAN}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{8}{section.4}\protected@file@percent }
\acronymused{GW}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Waveform quality}{8}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Interpolation}{8}{subsection.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Examples of \ac {GW} burst signals generated by a conditional generative adversarial network. By row: Sine-Gaussian, Ringdown, White-noise burst, Gaussian pulse, Binary black hole merger.\relax }}{9}{figure.caption.10}\protected@file@percent }
\acronymused{GW}
\newlabel{fig:gen_signals}{{3}{9}{Examples of \ac {GW} burst signals generated by a conditional generative adversarial network. By row: Sine-Gaussian, Ringdown, White-noise burst, Gaussian pulse, Binary black hole merger.\relax }{figure.caption.10}{}}
\newlabel{fig:gen_signals@cref}{{[figure][3][]3}{[1][8][]9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Latent space interpolation}{9}{subsubsection.4.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Latent space linear interpolation, class space is held constant.\relax }}{10}{figure.caption.11}\protected@file@percent }
\newlabel{fig:z_interp}{{4}{10}{Latent space linear interpolation, class space is held constant.\relax }{figure.caption.11}{}}
\newlabel{fig:z_interp@cref}{{[figure][4][]4}{[1][9][]10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Class space interpolation}{10}{subsubsection.4.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Class space linear interpolation, class space is held constant. Top row: gaussian blip to sine-gaussian, middle row: white noise burst to ringdown, bottom row: sine-gaussian to BBH.\relax }}{11}{figure.caption.12}\protected@file@percent }
\newlabel{fig:c_interp}{{5}{11}{Class space linear interpolation, class space is held constant. Top row: gaussian blip to sine-gaussian, middle row: white noise burst to ringdown, bottom row: sine-gaussian to BBH.\relax }{figure.caption.12}{}}
\newlabel{fig:c_interp@cref}{{[figure][5][]5}{[1][10][]11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Using a GAN to generate unmodelled waveforms}{11}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}CNN analysis}{11}{subsection.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces GAN generations where the class vectors are sampled from the 4-D plane and sampled uniformly in the class space.\relax }}{12}{figure.caption.13}\protected@file@percent }
\newlabel{fig:unmodelled_samples}{{6}{12}{GAN generations where the class vectors are sampled from the 4-D plane and sampled uniformly in the class space.\relax }{figure.caption.13}{}}
\newlabel{fig:unmodelled_samples@cref}{{[figure][6][]6}{[1][11][]12}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusions}{13}{section.5}\protected@file@percent }
\acronymused{GW}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Efficiency curves comparing the performance of CNNs trained on conditional generations (top), simplex generations (middle), uniform generations (bottom) for a fixed false alarm rate of $10^{-3}$.\relax }}{14}{figure.caption.14}\protected@file@percent }
\newlabel{fig:roc_curves}{{7}{14}{Efficiency curves comparing the performance of CNNs trained on conditional generations (top), simplex generations (middle), uniform generations (bottom) for a fixed false alarm rate of $10^{-3}$.\relax }{figure.caption.14}{}}
\newlabel{fig:roc_curves@cref}{{[figure][7][]7}{[1][13][]14}}
\bibdata{iopart-num}
\bibcite{Abbott2016}{1}
\bibcite{Prospects-dets}{2}
\bibcite{AdvLIGO}{3}
\bibcite{AdvLIGO2}{4}
\bibcite{AdvVIRGO}{5}
\bibcite{Abbott2016a}{6}
\bibcite{Abbott2017}{7}
\bibcite{Abbott2017a}{8}
\bibcite{Abbott2017b}{9}
\bibcite{Fryer_2003}{10}
\bibcite{Andersson_2001}{11}
\bibcite{Baiotti_2007}{12}
\bibcite{Owen1998}{13}
\bibcite{Klimenko_2008}{14}
\bibcite{Aso_2008}{15}
\bibcite{Gabbard2017}{16}
\bibcite{Gebhard_2019}{17}
\bibcite{Krastev_2020}{18}
\bibcite{Bahaadini}{19}
\bibcite{George_2018}{20}
\bibcite{Razzano_2018}{21}
\bibcite{gabbard2019bayesian}{22}
\bibcite{shen2019deterministic}{23}
\bibcite{green2020gravitationalwave}{24}
\bibcite{Goodfellow2014}{25}
\bibcite{brock2018large}{26}
\bibcite{karras2019analyzing}{27}
\bibcite{reed2016generative}{28}
\bibcite{liang2017dual}{29}
\bibcite{esteban2017realvalued}{30}
\bibcite{Nash1950}{31}
\bibcite{cgan}{32}
\bibcite{isola2016imagetoimage}{33}
\bibcite{Khan_2016}{34}
\bibcite{lalsuite}{35}
\bibcite{Abbott_2019}{36}
\bibcite{Radford2015}{37}
\bibcite{DBLP:journals/corr/abs-1809-11096}{38}
\@writefile{toc}{\contentsline {section}{\numberline {Appendix A}List of hyperparameters}{17}{appendix.A}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {A1}{\ignorespaces ACGAN architecture\relax }}{17}{table.caption.16}\protected@file@percent }
\newlabel{Tab:hyperparameters}{{A1}{17}{ACGAN architecture\relax }{table.caption.16}{}}
\newlabel{Tab:hyperparameters@cref}{{[table][1][2147483647,1]A1}{[1][17][]17}}
\@writefile{toc}{\contentsline {section}{\numberline {Appendix B}Many more generated examples}{17}{appendix.B}\protected@file@percent }
