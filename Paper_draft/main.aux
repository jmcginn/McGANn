\relax 
\providecommand\hyper@newdestlabel[2]{}
\bibstyle{iopart-num_custom}
\AC@reset@newl@bel
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Abbott2016}
\citation{Prospects-dets}
\citation{AdvLIGO}
\citation{AdvLIGO2}
\citation{AdvVIRGO}
\citation{Abbott2016a}
\citation{Abbott2017}
\citation{Abbott2017a}
\citation{Abbott2017b}
\citation{Owen1998}
\providecommand \oddpage@label [2]{}
\newacro{GW}[GW]{Gravitational wave}
\newacro{GAN}[GAN]{generative adversarial network}
\newacro{CGAN}[CGAN]{conditional generative adversarial network}
\newacro{ACGAN}[ACGAN]{auxilliary conditional generative adversarial network}
\newacro{DCGAN}[DCGAN]{deep convolutional generative adversarial network}
\newacro{CNN}[CNN]{convolutional neural networks}
\newacro{BBH}[BBH]{binary black hole}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{Klimenko_2008}
\citation{Aso_2008}
\citation{Gabbard2017}
\citation{Gebhard_2019}
\citation{Krastev_2020}
\citation{Bahaadini}
\citation{George_2018}
\citation{Razzano_2018}
\citation{gabbard2019bayesian}
\citation{shen2019deterministic}
\citation{green2020gravitationalwave}
\AC@undonewlabel{acro:GW}
\newlabel{acro:GW}{{1}{2}{Introduction}{section*.1}{}}
\newlabel{acro:GW@cref}{{[section][1][]1}{[1][2][]2}}
\acronymused{GW}
\acronymused{GW}
\acronymused{GW}
\acronymused{GW}
\acronymused{GW}
\acronymused{GW}
\acronymused{GW}
\@writefile{toc}{\contentsline {section}{\numberline {2}Generative Adversarial Networks}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Artificial neural networks}{2}{subsection.2.1}\protected@file@percent }
\newlabel{fig:perceptron}{{1a}{3}{Subfigure 1a}{subfigure.1.1}{}}
\newlabel{sub@fig:perceptron}{{(a)}{a}{Subfigure 1a\relax }{subfigure.1.1}{}}
\newlabel{fig:perceptron@cref}{{[subfigure][1][1]1a}{[1][2][]3}}
\newlabel{fig:tanh_activation}{{1b}{3}{Subfigure 1b}{subfigure.1.2}{}}
\newlabel{sub@fig:tanh_activation}{{(b)}{b}{Subfigure 1b\relax }{subfigure.1.2}{}}
\newlabel{fig:tanh_activation@cref}{{[subfigure][2][1]1b}{[1][2][]3}}
\newlabel{fig:neural_network}{{1c}{3}{Subfigure 1c}{subfigure.1.3}{}}
\newlabel{sub@fig:neural_network}{{(c)}{c}{Subfigure 1c\relax }{subfigure.1.3}{}}
\newlabel{fig:neural_network@cref}{{[subfigure][3][1]1c}{[1][2][]3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Neural Networks (a) A single neuron taking a vector of inputs and returning a singular output based on the weights, bias and activation function of the network. (b) The hyperbolic tangent used as an activation function. (c) A fully connected neural network containing two hidden layers that performs a mapping of an input vector to a singular output. \textbf  {\leavevmode {\color  {orange}MICHAEL: Equation in the neuron looks very small}}\relax }}{3}{figure.caption.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{3}{subfigure.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{3}{subfigure.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{3}{subfigure.1.3}\protected@file@percent }
\newlabel{eqn:neuron}{{1}{3}{Artificial neural networks}{equation.2.1}{}}
\newlabel{eqn:neuron@cref}{{[equation][1][]1}{[1][3][]3}}
\citation{Goodfellow2014}
\citation{brock2018large}
\citation{karras2019analyzing}
\citation{reed2016generative}
\citation{liang2017dual}
\citation{esteban2017realvalued}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}GANs}{4}{subsection.2.2}\protected@file@percent }
\AC@undonewlabel{acro:GAN}
\newlabel{acro:GAN}{{2.2}{4}{GANs}{section*.3}{}}
\newlabel{acro:GAN@cref}{{[subsection][2][2]2.2}{[1][4][]4}}
\acronymused{GAN}
\acronymused{GAN}
\acronymused{GAN}
\acronymused{GAN}
\newlabel{equation:GANloss}{{2}{4}{GANs}{equation.2.2}{}}
\newlabel{equation:GANloss@cref}{{[equation][2][]2}{[1][4][]4}}
\citation{Nash1950}
\citation{cgan}
\citation{isola2016imagetoimage}
\citation{Khan_2016}
\citation{lalsuite}
\citation{Abbott_2019}
\acronymused{GAN}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Conditional GANs}{5}{subsection.2.3}\protected@file@percent }
\acronymused{GAN}
\AC@undonewlabel{acro:CGAN}
\newlabel{acro:CGAN}{{2.3}{5}{Conditional GANs}{section*.4}{}}
\newlabel{acro:CGAN@cref}{{[subsection][3][2]2.3}{[1][5][]5}}
\acronymused{CGAN}
\newlabel{equation:cGANloss}{{3}{5}{Conditional GANs}{equation.2.3}{}}
\newlabel{equation:cGANloss@cref}{{[equation][3][]3}{[1][5][]5}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{5}{section.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Burst training parameters\relax }}{5}{table.caption.6}\protected@file@percent }
\newlabel{Tab:training_parms}{{1}{5}{Burst training parameters\relax }{table.caption.6}{}}
\newlabel{Tab:training_parms@cref}{{[table][1][]1}{[1][5][]5}}
\citation{Radford2015}
\citation{DBLP:journals/corr/abs-1809-11096}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Comparison of the original GAN method and the Conditional-GAN method. For CGANs the training data requires a label denoting its class that is also fed to the generator which then learns to generate waveforms based on the input label.\relax }}{6}{figure.caption.5}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:gan_comparison}{{2}{6}{Comparison of the original GAN method and the Conditional-GAN method. For CGANs the training data requires a label denoting its class that is also fed to the generator which then learns to generate waveforms based on the input label.\relax }{figure.caption.5}{}}
\newlabel{fig:gan_comparison@cref}{{[figure][2][]2}{[1][5][]6}}
\acronymused{GAN}
\AC@undonewlabel{acro:BBH}
\newlabel{acro:BBH}{{3}{6}{Methodology}{section*.7}{}}
\newlabel{acro:BBH@cref}{{[section][3][]3}{[1][5][]6}}
\acronymused{BBH}
\citation{Radford2015}
\citation{DBLP:journals/corr/abs-1809-11096}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Architecture details}{7}{subsection.3.1}\protected@file@percent }
\acronymused{GAN}
\AC@undonewlabel{acro:DCGAN}
\newlabel{acro:DCGAN}{{3.1}{7}{Architecture details}{section*.8}{}}
\newlabel{acro:DCGAN@cref}{{[subsection][1][3]3.1}{[1][6][]7}}
\acronymused{DCGAN}
\acronymused{GAN}
\AC@undonewlabel{acro:CNN}
\newlabel{acro:CNN}{{3.1}{7}{Architecture details}{section*.9}{}}
\newlabel{acro:CNN@cref}{{[subsection][1][3]3.1}{[1][6][]7}}
\acronymused{CNN}
\acronymused{GAN}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{7}{section.4}\protected@file@percent }
\acronymused{GW}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Waveform quality}{8}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Interpolation}{8}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Latent space interpolation}{8}{subsection.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Examples of \ac {GW} burst signals generated by a conditional generative adversarial network. Top row shows examples from the training set. By row: Sine-Gaussian, Ringdown, White-noise burst, Gaussian pulse, Binary black hole merger.\relax }}{9}{figure.caption.10}\protected@file@percent }
\acronymused{GW}
\newlabel{fig:train}{{3}{9}{Examples of \ac {GW} burst signals generated by a conditional generative adversarial network. Top row shows examples from the training set. By row: Sine-Gaussian, Ringdown, White-noise burst, Gaussian pulse, Binary black hole merger.\relax }{figure.caption.10}{}}
\newlabel{fig:train@cref}{{[figure][3][]3}{[1][8][]9}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Latent space linear interpolation, class space is held constant.\relax }}{10}{figure.caption.11}\protected@file@percent }
\newlabel{fig:c_interp}{{4}{10}{Latent space linear interpolation, class space is held constant.\relax }{figure.caption.11}{}}
\newlabel{fig:c_interp@cref}{{[figure][4][]4}{[1][10][]10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Class space interpolation}{10}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Sampling from simplex section}{11}{subsection.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Vector Arithmetic}{11}{subsection.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusions}{11}{section.5}\protected@file@percent }
\acronymused{GW}
\bibdata{iopart-num}
\bibcite{Abbott2016}{1}
\bibcite{Prospects-dets}{2}
\bibcite{AdvLIGO}{3}
\bibcite{AdvLIGO2}{4}
\bibcite{AdvVIRGO}{5}
\bibcite{Abbott2016a}{6}
\bibcite{Abbott2017}{7}
\bibcite{Abbott2017a}{8}
\bibcite{Abbott2017b}{9}
\bibcite{Owen1998}{10}
\bibcite{Klimenko_2008}{11}
\bibcite{Aso_2008}{12}
\bibcite{Gabbard2017}{13}
\bibcite{gabbard2019bayesian}{14}
\bibcite{Goodfellow2014}{15}
\bibcite{brock2018large}{16}
\bibcite{karras2019analyzing}{17}
\bibcite{reed2016generative}{18}
\bibcite{liang2017dual}{19}
\bibcite{esteban2017realvalued}{20}
\bibcite{Nash1950}{21}
\bibcite{cgan}{22}
\bibcite{odena2016conditional}{23}
\bibcite{Radford2015}{24}
\bibcite{DBLP:journals/corr/abs-1809-11096}{25}
\bibcite{lalsuite}{26}
\@writefile{toc}{\contentsline {section}{\numberline {Appendix A}List of hyperparameters}{14}{appendix.A}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {A1}{\ignorespaces ACGAN architecture\relax }}{14}{table.caption.13}\protected@file@percent }
\newlabel{Tab:hyperparameters}{{A1}{14}{ACGAN architecture\relax }{table.caption.13}{}}
\newlabel{Tab:hyperparameters@cref}{{[table][1][2147483647,1]A1}{[1][14][]14}}
\@writefile{toc}{\contentsline {section}{\numberline {Appendix B}Many more generated examples}{14}{appendix.B}\protected@file@percent }
